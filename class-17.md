# [Table of Contents](https://wondwosentsige.github.io/code-401-reading-notes/Home)

## Web scraping

Web scraping, web harvesting, or web data extraction is data scraping used for extracting data from websites. The web scraping software may directly access the World Wide Web using the Hypertext Transfer Protocol or a web browser. While web scraping can be done manually by a software user, the term typically refers to automated processes implemented using a bot or web crawler. It is a form of copying in which specific data is gathered and copied from the web, typically into a central local database or spreadsheet, for later retrieval or analysis.

Web scraping is a technique to automatically access and extract large amounts of information from a website, which can save a huge amount of time and effort.

### Important notes about web scraping:

Read through the websiteâ€™s Terms and Conditions to understand how you can legally use the data. Most sites prohibit you from using the data for commercial purposes.

Make sure you are not downloading data at too rapid a rate because this may break the website. You may potentially be blocked from the site as well.

Read the following link for a step by step guide to webscrap

[how to Web scrape with Python in 4 minutes](https://towardsdatascience.com/how-to-web-scrape-with-python-in-4-minutes-bc49186a8460)

**How can websites detect and block web scraping?**

Websites can use different mechanisms to detect a scraper/spider from a normal user. Some of these methods are enumerated below:

Unusual traffic/high download rate especially from a single client/or IP address within a short time span.

Repetitive tasks performed on the website in the same browsing pattern â€“ based on an assumption that a human user wonâ€™t perform the same repetitive tasks all the time.

Checking if you are real browser â€“ A simple check is to try and execute javascript. Smarter tools can go a lot more and check your Graphic cards and CPUs ðŸ˜‰ to make sure you are coming from real browser.

Detection through honeypots â€“ these honeypots are usually links which arenâ€™t visible to a normal user but only to a spider. When a scraper/spider tries to access the link, the alarms are tripped.























...............................................................................

__Attributions for the following Reference materials and their authors__

[wikipedia.org - web scrapping](https://en.wikipedia.org/wiki/Web_scraping)

[how to Web scrape with Python in 4 minutes - Julia kho](https://towardsdatascience.com/how-to-web-scrape-with-python-in-4-minutes-bc49186a8460)

[How to scrape websites without getting blocked](https://www.scrapehero.com/how-to-prevent-getting-blacklisted-while-scraping/)

[>> NEXT (Read: Class 18)](https://wondwosentsige.github.io/code-401-reading-note/class-18)